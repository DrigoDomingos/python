{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct  4 21:39:52 2017\n",
    "\n",
    "@author: bhavesh\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "\n",
    "cwd=os.getcwd()+'/'\n",
    "\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_test = pd.read_csv('input/test.csv')\n",
    "\n",
    "target_train = df_train['target'].values\n",
    "id_test = df_test['id'].values\n",
    "\n",
    "df_train=df_train.drop(['target','id'],axis=1)\n",
    "df_test=df_test.drop(['id'], axis = 1)\n",
    "combine= pd.concat([df_train,df_test],axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing rounding/binding\n",
    "#combine1= combine\n",
    "\n",
    "float_features = [a for a in combine.columns if combine[a].dtypes =='float64']\n",
    "\n",
    "for column in float_features:\n",
    "    combine[column] = round(combine[column],1)\n",
    "    \n",
    "#combine.head()\n",
    "#combine1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (595212, 227)\n",
      "The test shape is: (892816, 227)\n",
      "[0]\ttrain-gini:0.213558\tvalid-gini:0.219502\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[5]\ttrain-gini:0.243139\tvalid-gini:0.243406\n",
      "[10]\ttrain-gini:0.244421\tvalid-gini:0.243173\n",
      "[15]\ttrain-gini:0.246818\tvalid-gini:0.244675\n",
      "[20]\ttrain-gini:0.249014\tvalid-gini:0.246123\n",
      "[25]\ttrain-gini:0.248846\tvalid-gini:0.24567\n",
      "[30]\ttrain-gini:0.250141\tvalid-gini:0.246227\n",
      "[35]\ttrain-gini:0.2518\tvalid-gini:0.24688\n",
      "[40]\ttrain-gini:0.252408\tvalid-gini:0.24705\n",
      "[45]\ttrain-gini:0.252903\tvalid-gini:0.24671\n",
      "[50]\ttrain-gini:0.253228\tvalid-gini:0.246675\n",
      "[55]\ttrain-gini:0.253632\tvalid-gini:0.246556\n",
      "[60]\ttrain-gini:0.254815\tvalid-gini:0.247479\n",
      "[65]\ttrain-gini:0.2559\tvalid-gini:0.247599\n",
      "[70]\ttrain-gini:0.256536\tvalid-gini:0.248137\n",
      "[75]\ttrain-gini:0.256457\tvalid-gini:0.247688\n",
      "[80]\ttrain-gini:0.257421\tvalid-gini:0.248281\n",
      "[85]\ttrain-gini:0.258962\tvalid-gini:0.249357\n",
      "[90]\ttrain-gini:0.260108\tvalid-gini:0.250185\n",
      "[95]\ttrain-gini:0.261373\tvalid-gini:0.250708\n",
      "[100]\ttrain-gini:0.262298\tvalid-gini:0.250689\n",
      "[105]\ttrain-gini:0.263019\tvalid-gini:0.250976\n",
      "[110]\ttrain-gini:0.26478\tvalid-gini:0.252173\n",
      "[115]\ttrain-gini:0.265772\tvalid-gini:0.252706\n",
      "[120]\ttrain-gini:0.267312\tvalid-gini:0.253403\n",
      "[125]\ttrain-gini:0.2696\tvalid-gini:0.254706\n",
      "[130]\ttrain-gini:0.271098\tvalid-gini:0.255308\n",
      "[135]\ttrain-gini:0.273283\tvalid-gini:0.256303\n",
      "[140]\ttrain-gini:0.274737\tvalid-gini:0.256841\n",
      "[145]\ttrain-gini:0.276475\tvalid-gini:0.257547\n",
      "[150]\ttrain-gini:0.278882\tvalid-gini:0.258962\n",
      "[155]\ttrain-gini:0.280782\tvalid-gini:0.2604\n",
      "[160]\ttrain-gini:0.282085\tvalid-gini:0.260725\n",
      "[165]\ttrain-gini:0.284517\tvalid-gini:0.262242\n",
      "[170]\ttrain-gini:0.286384\tvalid-gini:0.263326\n",
      "[175]\ttrain-gini:0.288105\tvalid-gini:0.263892\n",
      "[180]\ttrain-gini:0.290027\tvalid-gini:0.264979\n",
      "[185]\ttrain-gini:0.292228\tvalid-gini:0.266635\n",
      "[190]\ttrain-gini:0.293608\tvalid-gini:0.267291\n",
      "[195]\ttrain-gini:0.295391\tvalid-gini:0.267963\n",
      "[200]\ttrain-gini:0.297055\tvalid-gini:0.268762\n",
      "[205]\ttrain-gini:0.298749\tvalid-gini:0.269751\n",
      "[210]\ttrain-gini:0.300268\tvalid-gini:0.270227\n",
      "[215]\ttrain-gini:0.302064\tvalid-gini:0.271187\n",
      "[220]\ttrain-gini:0.303282\tvalid-gini:0.271604\n",
      "[225]\ttrain-gini:0.304645\tvalid-gini:0.271989\n",
      "[230]\ttrain-gini:0.306028\tvalid-gini:0.272581\n",
      "[235]\ttrain-gini:0.307923\tvalid-gini:0.273246\n",
      "[240]\ttrain-gini:0.309253\tvalid-gini:0.273838\n",
      "[245]\ttrain-gini:0.310495\tvalid-gini:0.274436\n",
      "[250]\ttrain-gini:0.311778\tvalid-gini:0.274753\n",
      "[255]\ttrain-gini:0.312922\tvalid-gini:0.275437\n",
      "[260]\ttrain-gini:0.314205\tvalid-gini:0.275789\n",
      "[265]\ttrain-gini:0.315591\tvalid-gini:0.275977\n",
      "[270]\ttrain-gini:0.316903\tvalid-gini:0.276604\n",
      "[275]\ttrain-gini:0.317931\tvalid-gini:0.277121\n",
      "[280]\ttrain-gini:0.319029\tvalid-gini:0.277265\n",
      "[285]\ttrain-gini:0.320329\tvalid-gini:0.277933\n",
      "[290]\ttrain-gini:0.321475\tvalid-gini:0.278248\n",
      "[295]\ttrain-gini:0.322444\tvalid-gini:0.278604\n",
      "[300]\ttrain-gini:0.323722\tvalid-gini:0.279064\n",
      "[305]\ttrain-gini:0.324733\tvalid-gini:0.279266\n",
      "[310]\ttrain-gini:0.325621\tvalid-gini:0.27968\n",
      "[315]\ttrain-gini:0.326434\tvalid-gini:0.279945\n",
      "[320]\ttrain-gini:0.327445\tvalid-gini:0.28035\n",
      "[325]\ttrain-gini:0.328594\tvalid-gini:0.280777\n",
      "[330]\ttrain-gini:0.329452\tvalid-gini:0.281014\n",
      "[335]\ttrain-gini:0.330617\tvalid-gini:0.281382\n",
      "[340]\ttrain-gini:0.331621\tvalid-gini:0.281474\n",
      "[345]\ttrain-gini:0.332573\tvalid-gini:0.281805\n",
      "[350]\ttrain-gini:0.333647\tvalid-gini:0.282136\n",
      "[355]\ttrain-gini:0.334851\tvalid-gini:0.282426\n",
      "[360]\ttrain-gini:0.336\tvalid-gini:0.282637\n",
      "[365]\ttrain-gini:0.336952\tvalid-gini:0.282912\n",
      "[370]\ttrain-gini:0.337937\tvalid-gini:0.283067\n",
      "[375]\ttrain-gini:0.339106\tvalid-gini:0.283278\n",
      "[380]\ttrain-gini:0.340153\tvalid-gini:0.283453\n",
      "[385]\ttrain-gini:0.341383\tvalid-gini:0.283675\n",
      "[390]\ttrain-gini:0.342316\tvalid-gini:0.283766\n",
      "[395]\ttrain-gini:0.343386\tvalid-gini:0.283901\n",
      "[400]\ttrain-gini:0.344352\tvalid-gini:0.284147\n",
      "[405]\ttrain-gini:0.34522\tvalid-gini:0.284291\n",
      "[410]\ttrain-gini:0.346362\tvalid-gini:0.284655\n",
      "[415]\ttrain-gini:0.34727\tvalid-gini:0.284929\n",
      "[420]\ttrain-gini:0.347951\tvalid-gini:0.285066\n",
      "[425]\ttrain-gini:0.348797\tvalid-gini:0.285307\n",
      "[430]\ttrain-gini:0.349561\tvalid-gini:0.285398\n",
      "[435]\ttrain-gini:0.350229\tvalid-gini:0.285587\n",
      "[440]\ttrain-gini:0.351076\tvalid-gini:0.285698\n",
      "[445]\ttrain-gini:0.351872\tvalid-gini:0.285636\n",
      "[450]\ttrain-gini:0.352802\tvalid-gini:0.28559\n",
      "[455]\ttrain-gini:0.353597\tvalid-gini:0.285584\n",
      "[460]\ttrain-gini:0.354475\tvalid-gini:0.28593\n",
      "[465]\ttrain-gini:0.355363\tvalid-gini:0.285874\n",
      "[470]\ttrain-gini:0.356227\tvalid-gini:0.286073\n",
      "[475]\ttrain-gini:0.357173\tvalid-gini:0.286272\n",
      "[480]\ttrain-gini:0.357766\tvalid-gini:0.286235\n",
      "[485]\ttrain-gini:0.358819\tvalid-gini:0.286407\n",
      "[490]\ttrain-gini:0.359769\tvalid-gini:0.286553\n",
      "[495]\ttrain-gini:0.360763\tvalid-gini:0.286648\n",
      "[500]\ttrain-gini:0.361639\tvalid-gini:0.286828\n",
      "[505]\ttrain-gini:0.362422\tvalid-gini:0.286942\n",
      "[510]\ttrain-gini:0.363139\tvalid-gini:0.286944\n",
      "[515]\ttrain-gini:0.364038\tvalid-gini:0.286965\n",
      "[520]\ttrain-gini:0.36474\tvalid-gini:0.286897\n",
      "[525]\ttrain-gini:0.365442\tvalid-gini:0.286916\n",
      "[530]\ttrain-gini:0.366421\tvalid-gini:0.286822\n",
      "[535]\ttrain-gini:0.367206\tvalid-gini:0.286796\n",
      "[540]\ttrain-gini:0.367968\tvalid-gini:0.286835\n",
      "[545]\ttrain-gini:0.368623\tvalid-gini:0.286846\n",
      "[550]\ttrain-gini:0.369437\tvalid-gini:0.286952\n",
      "[555]\ttrain-gini:0.370283\tvalid-gini:0.287184\n",
      "[560]\ttrain-gini:0.370953\tvalid-gini:0.287221\n",
      "[565]\ttrain-gini:0.371728\tvalid-gini:0.287265\n",
      "[570]\ttrain-gini:0.372435\tvalid-gini:0.287417\n",
      "[575]\ttrain-gini:0.37337\tvalid-gini:0.287461\n",
      "[580]\ttrain-gini:0.374054\tvalid-gini:0.287611\n",
      "[585]\ttrain-gini:0.374928\tvalid-gini:0.287565\n",
      "[590]\ttrain-gini:0.375524\tvalid-gini:0.287589\n",
      "[595]\ttrain-gini:0.376312\tvalid-gini:0.287609\n",
      "[600]\ttrain-gini:0.377083\tvalid-gini:0.287866\n",
      "[605]\ttrain-gini:0.37775\tvalid-gini:0.287838\n",
      "[610]\ttrain-gini:0.378165\tvalid-gini:0.287937\n",
      "[615]\ttrain-gini:0.378776\tvalid-gini:0.287968\n",
      "[620]\ttrain-gini:0.379608\tvalid-gini:0.288013\n",
      "[625]\ttrain-gini:0.380271\tvalid-gini:0.288024\n",
      "[630]\ttrain-gini:0.380883\tvalid-gini:0.288167\n",
      "[635]\ttrain-gini:0.381555\tvalid-gini:0.288247\n",
      "[640]\ttrain-gini:0.382289\tvalid-gini:0.288292\n",
      "[645]\ttrain-gini:0.382948\tvalid-gini:0.288201\n",
      "[650]\ttrain-gini:0.383857\tvalid-gini:0.288165\n",
      "[655]\ttrain-gini:0.384358\tvalid-gini:0.288078\n",
      "[660]\ttrain-gini:0.385088\tvalid-gini:0.288181\n",
      "[665]\ttrain-gini:0.385765\tvalid-gini:0.288183\n",
      "[670]\ttrain-gini:0.386327\tvalid-gini:0.288219\n",
      "[675]\ttrain-gini:0.386975\tvalid-gini:0.288266\n",
      "[680]\ttrain-gini:0.387669\tvalid-gini:0.288189\n",
      "[685]\ttrain-gini:0.388413\tvalid-gini:0.288163\n",
      "[690]\ttrain-gini:0.389224\tvalid-gini:0.28817\n",
      "[695]\ttrain-gini:0.389867\tvalid-gini:0.288115\n",
      "[700]\ttrain-gini:0.390441\tvalid-gini:0.288018\n",
      "[705]\ttrain-gini:0.391111\tvalid-gini:0.288106\n",
      "[710]\ttrain-gini:0.391887\tvalid-gini:0.288135\n",
      "[715]\ttrain-gini:0.392485\tvalid-gini:0.288119\n",
      "[720]\ttrain-gini:0.393194\tvalid-gini:0.288089\n",
      "[725]\ttrain-gini:0.393947\tvalid-gini:0.288138\n",
      "[730]\ttrain-gini:0.394806\tvalid-gini:0.28802\n",
      "[735]\ttrain-gini:0.395268\tvalid-gini:0.288057\n",
      "[740]\ttrain-gini:0.395834\tvalid-gini:0.28803\n",
      "[745]\ttrain-gini:0.396451\tvalid-gini:0.288141\n",
      "[750]\ttrain-gini:0.397206\tvalid-gini:0.288093\n",
      "[755]\ttrain-gini:0.397769\tvalid-gini:0.28808\n",
      "[760]\ttrain-gini:0.398368\tvalid-gini:0.287953\n",
      "[765]\ttrain-gini:0.398927\tvalid-gini:0.287922\n",
      "[770]\ttrain-gini:0.399456\tvalid-gini:0.287918\n",
      "[775]\ttrain-gini:0.400094\tvalid-gini:0.287908\n",
      "Stopping. Best iteration:\n",
      "[676]\ttrain-gini:0.38713\tvalid-gini:0.288296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Performing one hot encoding\n",
    "cat_features = [a for a in combine.columns if a.endswith('cat')]\n",
    "for column in cat_features:\n",
    "    temp=pd.get_dummies(pd.Series(combine[column]))\n",
    "    combine=pd.concat([combine,temp],axis=1)\n",
    "    combine=combine.drop([column],axis=1)\n",
    "\n",
    "df_train=combine[:df_train.shape[0]]\n",
    "df_test=combine[df_train.shape[0]:]\n",
    "\n",
    "train = np.array(df_train)\n",
    "test = np.array(df_test)\n",
    "\n",
    "print (\"The train shape is:\",train.shape)\n",
    "print ('The test shape is:',test.shape)\n",
    "\n",
    "\n",
    "# TODO: Import any additional functionality you may need here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train, target_train, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_preds = []\n",
    "\n",
    "\n",
    "#K = 5\n",
    "#kf = KFold(n_splits = K, random_state = 3228,shuffle=True)\n",
    "\n",
    "\n",
    "#for train_index, test_index in kf.split(train):\n",
    "#    train_X, valid_X = train[train_index], train[test_index]\n",
    "#    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "xgb_params = {'eta': 0.02, 'max_depth': 5, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "\n",
    "d_train = xgb.DMatrix(train_X, train_y)\n",
    "d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "d_test = xgb.DMatrix(test)\n",
    "    \n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "model = xgb.train(xgb_params, d_train, 2000,  watchlist, feval=gini_xgb, maximize=True, verbose_eval=5, early_stopping_rounds=100)\n",
    "                        \n",
    "xgb_pred = model.predict(d_test)\n",
    "xgb_preds.append(list(xgb_pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "#preds=[]\n",
    "#for i in range(len(xgb_preds[0])):\n",
    "#    sum=0\n",
    "#    for j in range(K):\n",
    "#        sum+=xgb_preds[j][i]\n",
    "#    preds.append(sum / K)\n",
    "\n",
    "#output = pd.DataFrame({'id': id_test, 'target': preds})\n",
    "#output.to_csv(\"{}-foldCV_avg_sub.csv\".format(K), index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trn_df = pd.read_csv(\"input/train.csv\")\n",
    "f_bins = [f for f in trn_df.columns if \"_bin\" in f]\n",
    "f_cats = [f for f in trn_df.columns if \"_cat\" in f]\n",
    "f_flts = [f for f in trn_df.columns if f not in f_bins + f_cats + [\"target\", \"id\"]]\n",
    "f_all = [f_bins + f_cats + f_flts]\n",
    "\n",
    "\n",
    "\n",
    "f_scores = pd.DataFrame(np.zeros((len(f_all), 2)), columns=[\"feature\", \"score\"])\n",
    "for i_f, f in enumerate(f_bins + f_cats + f_flts):\n",
    "    # Get the score for each feature\n",
    "    # If trn_df[f] has a negative score then - trn_df[f] has a positive one\n",
    "    # Remember it's all about sorting !\n",
    "    f_scores.loc[i_f] = [f, abs(gini_normalized(trn_df.target.values, trn_df[f].values))]\n",
    "f_scores.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "f_scores.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File generated!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "submission = pd.read_csv('output/sample_submission.csv')\n",
    "\n",
    "submission_output = submission\n",
    "\n",
    "submission_output['target'] = xgb_pred\n",
    "\n",
    "\n",
    "submission_output.to_csv('output/submission_output_xgb.csv',index=False)\n",
    "\n",
    "print (\"File generated!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
